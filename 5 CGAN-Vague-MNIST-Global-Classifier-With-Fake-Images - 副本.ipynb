{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tips\n",
    "* `tensor.squeeze()`: delete dimensions with size 1, egg. `[1, 28, 28] -> [28, 28]`\n",
    "* `tensor.flatten(start_dim=0)`: expend tensor to one dimension, egg. `[1, 28, 28] -> [784]`\n",
    "* `transforms.ToTensor()`:  convert `(H x W x C)` of `[0, 255]` to a torch.FloatTensor `(C x H x W)` of `[0.0, 1.0]`\n",
    "* `tensor.argmax(dim=1)`: return indices of the maximum values across a dimension\n",
    "* `torch.sum(t_x == t_x)`: compute the number of elements in x equals to that in y\n",
    "* `torch.cat(tensors, dim=0)`: concatenates tensor tuples\n",
    "* `torch.stack(tensors, dim=0)`: concatenates tensor tuples along a new dimension\n",
    "* `torch.unsqueeze(input, dim)`: insert a dimension of size one at the specified position to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T09:33:44.014898Z",
     "start_time": "2020-04-23T09:33:43.203940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as tvmodels\n",
    "from torch.autograd import Variable\n",
    "manualseed = 47\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create fake datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset with fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T09:34:16.086928Z",
     "start_time": "2020-04-23T09:34:16.072967Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf = 32):\n",
    "        super(Generator,self).__init__()\n",
    "        self.gen=nn.Sequential(\n",
    "            # 输入是 Z, 对Z进行卷积\n",
    "            nn.ConvTranspose2d(110, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 输入特征图大小. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 输入特征图大小. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 输入特征图大小. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf*2, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # 输入特征图大小. (nc) x 32 x 32\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x=self.gen(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FakeNumberDataset(Dataset):\n",
    "    def __init__(self, dataset_name=\"mnist\",transform=None):\n",
    "        \"\"\"\n",
    "            mix_ratio: real/fake\n",
    "        \"\"\"\n",
    "\n",
    "        if dataset_name==\"mnist\":\n",
    "            odataset = datasets.MNIST('MNIST_data', train=True, transform=transform)\n",
    "        elif dataset_name==\"fashion_mnist\":\n",
    "            odataset = datasets.FashionMNIST('MNIST_data', train=True, transform=transform)\n",
    "        elif dataset_name==\"cifar10\":\n",
    "            odataset = datasets.CIFAR10('MNIST_data', train=True, transform=transform)\n",
    "        else:\n",
    "            print(\"Wrong argument for dataset_name!\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "\n",
    "        self.label = []\n",
    "        self.items = []\n",
    "        ############################\n",
    "        n_z=100\n",
    "        ############################\n",
    "        #target_num = mix_ratio * fake_images.shape[0]\n",
    "        #self.added_real = 0 \n",
    "#         print(len(odataset))\n",
    "       \n",
    "        netG = Generator().to(device)\n",
    "        netG.load_state_dict(torch.load('C:\\\\Users\\\\lz172\\\\Desktop\\\\test\\\\attacker_model\\\\netG_params.pkl'))\n",
    "        for idx in range(len(odataset)):\n",
    "            x_idx, y_idx = odataset[idx]\n",
    "#             print(x_idx)\n",
    "            ###############################################\n",
    "            noise = torch.randn(1, 100)\n",
    "            labels_onehot = np.zeros((1,10))\n",
    "            labels_onehot[np.arange(1),y_idx]=1 # 这个9换成想生成的数字\n",
    "            noise=np.concatenate((noise.cpu().numpy(), labels_onehot),axis=1)\n",
    "            # 每张图片是0到9之间的数字\n",
    "            labels_onehot = Variable(torch.from_numpy(labels_onehot).float())\n",
    "#                 labels_onehot = Variable(torch.from_numpy(labels_onehot).float())\n",
    "            noise=noise.reshape([-1, 110, 1, 1])\n",
    "            noise=Variable(torch.from_numpy(noise).float())                \n",
    "            fake_image1 = netG(noise.to(device)).detach().cpu()\n",
    "            fake_image = torch.squeeze(fake_image1,0)\n",
    "            lamma = torch.rand(1)\n",
    "            x_idx = fake_image\n",
    "#                 x_idx = fake_image\n",
    "            self.items.append(x_idx)\n",
    "            self.label.append(y_idx)\n",
    "\n",
    "            ##############################################\n",
    "            \n",
    "                \n",
    "\n",
    "    def checkAddedRealImgs(self):\n",
    "        return self.added_real\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.items[idx], self.label[idx]\n",
    "\n",
    "# transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "# trainset = datasets.MNIST('MNIST_data', download=True, train=True, transform=transform)\n",
    "\n",
    "# train_dataset_with_fake = FakeNumberDataset(fake_images=fake_images[0:6000], mix_ratio=0.01, odataset=trainset)\n",
    "# trainloader = torch.utils.data.DataLoader(train_dataset_with_fake, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# testset = datasets.MNIST('MNIST_data', train=False, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "# print(\"Number of Train:\", len(train_dataset_with_fake), \"Number of Test:\", len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: create a neural network model (global classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T09:34:19.610332Z",
     "start_time": "2020-04-23T09:34:19.424207Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (lfc1): Linear(in_features=43264, out_features=100, bias=True)\n",
      "  (lfc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor param in test_m.parameters():\\n    print(type(param.data), param.size())\\n\\nx, y = next(iter(testloader))\\nprint(x.shape)\\nx = nn.Conv2d(3, 16, 3)(x)\\nprint(x.shape)\\nx = nn.MaxPool2d(2, stride=1)(x)\\nprint(x.shape)\\nx = nn.Conv2d(16, 64, 3)(x)\\nprint(x.shape)\\nx = nn.MaxPool2d(2, stride=1)(x)\\nprint(x.shape)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_channel=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(n_channel, 16, 3), nn.ReLU())\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=1)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 64, 3), nn.ReLU())\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.lfc1 = nn.Linear(64*26*26, 100)      # 这个4注意改掉\n",
    "        self.lfc2 = nn.Linear(100, 10)\n",
    "                                      \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return self.lfc2(self.lfc1(x))\n",
    "\n",
    "test_m = Model()\n",
    "print(test_m)\n",
    "\"\"\"\n",
    "for param in test_m.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "\n",
    "x, y = next(iter(testloader))\n",
    "print(x.shape)\n",
    "x = nn.Conv2d(3, 16, 3)(x)\n",
    "print(x.shape)\n",
    "x = nn.MaxPool2d(2, stride=1)(x)\n",
    "print(x.shape)\n",
    "x = nn.Conv2d(16, 64, 3)(x)\n",
    "print(x.shape)\n",
    "x = nn.MaxPool2d(2, stride=1)(x)\n",
    "print(x.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T05:02:10.013778Z",
     "start_time": "2020-02-29T05:02:10.010746Z"
    }
   },
   "source": [
    "### Step 3: train data (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T03:32:04.456194Z",
     "start_time": "2020-04-24T03:27:29.112215Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "number of imgs in train set: 60000\n",
      "Start training loop...\n",
      "-------------------------------------\n",
      "300 938\n",
      "600 938\n",
      "900 938\n",
      "[1\\2], loss: 0.025401920080184937, train accuracy: 0.9215666651725769, test accuracy: 0.08389999717473984.\n",
      "0m 8s (- 0m 8s) (1 50%)\n",
      "-------------------------------------\n",
      "300 938\n",
      "600 938\n",
      "900 938\n",
      "[2\\2], loss: 0.006574805360287428, train accuracy: 0.9910333156585693, test accuracy: 0.07519999891519547.\n",
      "0m 15s (- 0m 0s) (2 100%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    h = math.floor(m / 60)\n",
    "    m -= h * 60\n",
    "    return '%dm %ds' % (m, s) if h==0 else '%dh %dm %ds' % (h, m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def checktestaccur( m, testdataloader, datasetsize):\n",
    "    # test 用的是真实数据，包括6\n",
    "    m.eval()\n",
    "    positive = float(0)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        \n",
    "        for x, y in testdataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            yhat = m(x)\n",
    "            positive += torch.sum(yhat.argmax(dim=1) == y)\n",
    "#             pre = yhat.argmax(dim=1)\n",
    "# #             for i in range(len(y)):\n",
    "#                 if y[i].data == 6:\n",
    "#                     all_6 += 1\n",
    "#                     if pre[i].data == 6:\n",
    "#                         true_6 += 1\n",
    "\n",
    "    return positive/datasetsize\n",
    "        \n",
    "epoches = 2  # 2 is best, 3 is fine\n",
    "# change n_channel\n",
    "print(epoches)\n",
    "model = Model(n_channel=1).to(device)  \n",
    "optimizer = torch.optim.Adam(model.parameters()) \n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "###################################################\n",
    "transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "# Mnist or FashionMnist\n",
    "train_dataset_with_fake = FakeNumberDataset(dataset_name=\"mnist\",transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset_with_fake, batch_size=64, shuffle=True)\n",
    "# MNIST or FashionMNIST\n",
    "testset = datasets.MNIST('MNIST_data', train=False, transform=transform) \n",
    "# testset = datasets.CIFAR10('MNIST_data',  train=False, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True) \n",
    "###################################################\n",
    "\n",
    "losses = [] \n",
    "trainaccurs = []\n",
    "testaccurs = []\n",
    "epoch_sample = len(train_dataset_with_fake)    #    注意这个base数字\n",
    "print(\"number of imgs in train set:\", epoch_sample)\n",
    "start = time.time()\n",
    "print(\"Start training loop...\")\n",
    "for epoch in range(1, epoches+1):\n",
    "    print(\"-------------------------------------\")\n",
    "    accurate = float(0)\n",
    "    idx = 0\n",
    "    for x, y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        yhat = yhat.argmax(dim=1)\n",
    "        accurate += (y==yhat).float().sum()\n",
    "        idx += 1\n",
    "        if idx % 300 == 0:\n",
    "            print(idx, len(trainloader))\n",
    "        \n",
    "    losses.append(loss)\n",
    "\n",
    "    testaccur = checktestaccur(model, testloader, len(testset))    # 注意这里传进去的数字\n",
    "    testaccurs.append(testaccur)\n",
    "    trainaccurs.append(accurate/epoch_sample)\n",
    "    print(\"[{}\\{}], loss: {}, train accuracy: {}, test accuracy: {}.\".format(epoch, epoches, loss, accurate/epoch_sample, testaccur))\n",
    "    print('%s (%d %d%%)' % (timeSince(start, epoch / epoches), epoch, epoch / epoches * 100))\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(losses)+1), losses, '-ro')\n",
    "plt.title(\"Losses\")\n",
    "# plt.plot(range(len(testaccurs)), testaccurs, '-.go')\n",
    "# plt.plot(range(len(trainaccurs)), trainaccurs, '--bo')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Percentage')\n",
    "# plt.legend(['Loss', 'Test Accur', 'Train Accur'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4：画fake图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-11a30d075f7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreal_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfake_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "real_batch = next(iter(testloader))\n",
    "fake_batch = next(iter(trainloader))\n",
    "a = torch.var(real_batch[0])\n",
    "print(a)\n",
    "b = torch.var(fake_batch[0])\n",
    "print(b)\n",
    "# print(real_batch.shape)\n",
    "print(fake_batch[0].shape)\n",
    "print(real_batch[0].shape)\n",
    "c = torch.mean(real_batch[0])\n",
    "d = torch.mean(fake_batch[0])\n",
    "print(c)\n",
    "print(d)\n",
    "# print(img_list[2].shape)\n",
    "# 画出真实图像\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real_test Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:16], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "# b = torch.var(img_list[-1],(1,2,0))\n",
    "# print(b)\n",
    "# 画出来自最后一次训练的假图像\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(fake_batch[0].to(device)[:16], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "# b = torch.var(img_list[-1],(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FakeNumberDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-933137016000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m ])\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mFakeNumberDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mnist\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m# 29 30 35 49 77 93\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FakeNumberDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "def denormalize(y):\n",
    "    print(y.shape)\n",
    "    c, w, h = y.shape\n",
    "    assert c == 1, \"the first dimension of y should be 1!\"\n",
    "    mean = torch.tensor([0.5,])  # Failed\n",
    "    std = torch.tensor([0.5,])\n",
    "    realy = torch.zeros_like(y)\n",
    "    for i in range(c):\n",
    "        realy[i] = y[i] * std[i] + mean[i]\n",
    "    realy = torch.clamp(realy, 0, 1)\n",
    "#     print(realy)\n",
    "    return realy\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, ), std=(0.5,))\n",
    "])\n",
    "trainset =FakeNumberDataset(dataset_name=\"mnist\",transform=transform)\n",
    "# 29 30 35 49 77 93\n",
    "\n",
    "# x, y =  trainset[77]\n",
    "train_set = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "for i in range(len(train_set)):\n",
    "    x, y =  trainset[i]\n",
    "    if y==8:\n",
    "        print(y)\n",
    "        break\n",
    "plt.figure()\n",
    "plt.imshow(transforms.ToPILImage()(denormalize(x)))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(transforms.ToPILImage()(denormalize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:29:35.356636Z",
     "start_time": "2020-04-09T10:29:35.342252Z"
    }
   },
   "outputs": [],
   "source": [
    "## Method 1\n",
    "torch.save(model.state_dict(), \"MNIST-Classifier-purefake6train-epoch8-\")\n",
    "\n",
    "# the_model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(\"LSTM-Model-nonbd-Epoch17-0330-1927\"))\n",
    "\n",
    "## Method 2\n",
    "# torch.save(model, \"MyBatchModel-Epoch2-GRU-0328-0953\")\n",
    "# the_model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
